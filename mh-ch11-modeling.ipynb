{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-01-30T06:24:13.086325Z","iopub.execute_input":"2023-01-30T06:24:13.087514Z","iopub.status.idle":"2023-01-30T06:24:13.097199Z","shell.execute_reply.started":"2023-01-30T06:24:13.087469Z","shell.execute_reply":"2023-01-30T06:24:13.096043Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch # 파이토치 \nimport random\nimport numpy as np\nimport os\n\n# 시드값 고정\nseed = 50\nos.environ['PYTHONHASHSEED'] = str(seed)\nrandom.seed(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.cuda.manual_seed_all(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.enabled = False","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:24:13.099269Z","iopub.execute_input":"2023-01-30T06:24:13.100165Z","iopub.status.idle":"2023-01-30T06:24:13.111665Z","shell.execute_reply.started":"2023-01-30T06:24:13.100136Z","shell.execute_reply":"2023-01-30T06:24:13.110682Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:24:13.113168Z","iopub.execute_input":"2023-01-30T06:24:13.113443Z","iopub.status.idle":"2023-01-30T06:24:13.122110Z","shell.execute_reply.started":"2023-01-30T06:24:13.113420Z","shell.execute_reply":"2023-01-30T06:24:13.121174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# 데이터 경로\ndata_path = '/kaggle/input/aerial-cactus-identification/'\n\nlabels = pd.read_csv(data_path + 'train.csv')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:24:13.123633Z","iopub.execute_input":"2023-01-30T06:24:13.124003Z","iopub.status.idle":"2023-01-30T06:24:13.154724Z","shell.execute_reply.started":"2023-01-30T06:24:13.123968Z","shell.execute_reply":"2023-01-30T06:24:13.153770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from zipfile import ZipFile\n\n# 훈련 이미지 데이터 압축 풀기\nwith ZipFile(data_path + 'train.zip') as zipper:\n    zipper.extractall()\n    \n# 테스트 이미지 데이터 압축 풀기\nwith ZipFile(data_path + 'test.zip') as zipper:\n    zipper.extractall()","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:24:13.157687Z","iopub.execute_input":"2023-01-30T06:24:13.158136Z","iopub.status.idle":"2023-01-30T06:24:17.305599Z","shell.execute_reply.started":"2023-01-30T06:24:13.158100Z","shell.execute_reply":"2023-01-30T06:24:17.304465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# 훈련 데이터, 검증 데이터 분리\ntrain, valid = train_test_split(labels, \n                                test_size=0.1,\n                                stratify=labels['has_cactus'],\n                                random_state=50)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:24:17.307134Z","iopub.execute_input":"2023-01-30T06:24:17.307588Z","iopub.status.idle":"2023-01-30T06:24:17.325023Z","shell.execute_reply.started":"2023-01-30T06:24:17.307549Z","shell.execute_reply":"2023-01-30T06:24:17.323744Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import cv2 # OpenCV 라이브러리\nfrom torch.utils.data import Dataset # 데이터 생성을 위한 클래스\n\nclass ImageDataset(Dataset):\n    # 초기화 메서드(생성자)\n    def __init__(self, df, img_dir='./', transform=None):\n        super().__init__() # 상속받은 Dataset의 생성자 호출\n        # 전달받은 인수들 저장\n        self.df = df\n        self.img_dir = img_dir\n        self.transform = transform\n    \n    # 데이터셋 크기 반환 메서드 \n    def __len__(self):\n        return len(self.df)\n    \n    # 인덱스(idx)에 해당하는 데이터 반환 메서드 \n    def __getitem__(self, idx):\n        img_id = self.df.iloc[idx, 0]    # 이미지 ID\n        img_path = self.img_dir + img_id # 이미지 파일 경로 \n        image = cv2.imread(img_path)     # 이미지 파일 읽기 \n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # 이미지 색상 보정\n        label = self.df.iloc[idx, 1]     # 이미지 레이블(타깃값)\n\n        if self.transform is not None:\n            image = self.transform(image) # 변환기가 있다면 이미지 변환\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:24:17.327027Z","iopub.execute_input":"2023-01-30T06:24:17.327706Z","iopub.status.idle":"2023-01-30T06:24:17.539830Z","shell.execute_reply.started":"2023-01-30T06:24:17.327665Z","shell.execute_reply":"2023-01-30T06:24:17.538764Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms # 이미지 변환을 위한 모듈\n\n# 훈련 데이터용 변환기\ntransform_train = transforms.Compose([transforms.ToTensor(),\n                                      transforms.Pad(32, padding_mode='symmetric'),\n                                      transforms.RandomHorizontalFlip(),\n                                      transforms.RandomVerticalFlip(),\n                                      transforms.RandomRotation(10),\n                                      transforms.Normalize((0.485, 0.456, 0.406),\n                                                           (0.229, 0.224, 0.225))])\n\n# 검증 및 테스트 데이터용 변환기\ntransform_test= transforms.Compose([transforms.ToTensor(),\n                                    transforms.Pad(32, padding_mode='symmetric'),\n                                    transforms.Normalize((0.485, 0.456, 0.406),\n                                                         (0.229, 0.224, 0.225))])","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:25:01.608236Z","iopub.execute_input":"2023-01-30T06:25:01.608679Z","iopub.status.idle":"2023-01-30T06:25:01.843816Z","shell.execute_reply.started":"2023-01-30T06:25:01.608645Z","shell.execute_reply":"2023-01-30T06:25:01.842891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_train = ImageDataset(df=train, img_dir='train/', transform=transform_train)\ndataset_valid = ImageDataset(df=valid, img_dir='train/', transform=transform_test)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:31:05.801336Z","iopub.execute_input":"2023-01-30T06:31:05.801713Z","iopub.status.idle":"2023-01-30T06:31:05.810111Z","shell.execute_reply.started":"2023-01-30T06:31:05.801681Z","shell.execute_reply":"2023-01-30T06:31:05.809049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from torch.utils.data import DataLoader # 데이터 로더 클래스\n\nloader_train = DataLoader(dataset=dataset_train, batch_size=32, shuffle=True)\nloader_valid = DataLoader(dataset=dataset_valid, batch_size=32, shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:31:29.337405Z","iopub.execute_input":"2023-01-30T06:31:29.338069Z","iopub.status.idle":"2023-01-30T06:31:29.344817Z","shell.execute_reply.started":"2023-01-30T06:31:29.338033Z","shell.execute_reply":"2023-01-30T06:31:29.343862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.nn as nn # 신경망 모듈\nimport torch.nn.functional as F # 신경망 모듈에서 자주 사용되는 함수\n\nclass Model(nn.Module):\n    # 신경망 계층 정의\n    def __init__(self):\n        super().__init__() # 상속받은 nn.Module의 __init__() 메서드 호출\n        # 1 ~ 5번째 {합성곱, 배치 정규화, 최대 풀링} 계층 \n        self.layer1 = nn.Sequential(nn.Conv2d(in_channels=3, out_channels=32,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(32), # 배치 정규화\n                                    nn.LeakyReLU(), # LeakyReLU 활성화 함수\n                                    nn.MaxPool2d(kernel_size=2))\n\n        self.layer2 = nn.Sequential(nn.Conv2d(in_channels=32, out_channels=64,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(64),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        \n        self.layer3 = nn.Sequential(nn.Conv2d(in_channels=64, out_channels=128,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(128),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        \n        self.layer4 = nn.Sequential(nn.Conv2d(in_channels=128, out_channels=256,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(256),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        \n        self.layer5 = nn.Sequential(nn.Conv2d(in_channels=256, out_channels=512,\n                                              kernel_size=3, padding=2),\n                                    nn.BatchNorm2d(512),\n                                    nn.LeakyReLU(),\n                                    nn.MaxPool2d(kernel_size=2))\n        # 평균 풀링 계층 \n        self.avg_pool = nn.AvgPool2d(kernel_size=4) \n        # 전결합 계층\n        self.fc1 = nn.Linear(in_features=512 * 1 * 1, out_features=64)\n        self.fc2 = nn.Linear(in_features=64, out_features=2)\n\n    # 순전파 출력 정의 \n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        x = self.layer5(x)\n        x = self.avg_pool(x)\n        x = x.view(-1, 512 * 1 * 1) # 평탄화\n        x = self.fc1(x)\n        x = self.fc2(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:34:30.026874Z","iopub.execute_input":"2023-01-30T06:34:30.027536Z","iopub.status.idle":"2023-01-30T06:34:30.041214Z","shell.execute_reply.started":"2023-01-30T06:34:30.027503Z","shell.execute_reply":"2023-01-30T06:34:30.040220Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Model().to(device)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:35:52.616126Z","iopub.execute_input":"2023-01-30T06:35:52.616482Z","iopub.status.idle":"2023-01-30T06:35:56.051093Z","shell.execute_reply.started":"2023-01-30T06:35:52.616452Z","shell.execute_reply":"2023-01-30T06:35:56.049967Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 손실 함수\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:36:49.267725Z","iopub.execute_input":"2023-01-30T06:36:49.268149Z","iopub.status.idle":"2023-01-30T06:36:49.274655Z","shell.execute_reply.started":"2023-01-30T06:36:49.268098Z","shell.execute_reply":"2023-01-30T06:36:49.273517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# 옵티마이저\noptimizer = torch.optim.Adamax(model.parameters(), lr=0.00006)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:38:11.938144Z","iopub.execute_input":"2023-01-30T06:38:11.938587Z","iopub.status.idle":"2023-01-30T06:38:11.948621Z","shell.execute_reply.started":"2023-01-30T06:38:11.938549Z","shell.execute_reply":"2023-01-30T06:38:11.947576Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"epochs = 70 # 총 에폭\n\n# 총 에폭만큼 반복\nfor epoch in range(epochs):\n    epoch_loss = 0 # 에폭별 손실값 초기화\n    \n    # '반복 횟수'만큼 반복 \n    for images, labels in loader_train:\n        # 이미지, 레이블 데이터 미니배치를 장비에 할당 \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # 옵티마이저 내 기울기 초기화\n        optimizer.zero_grad()\n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 손실 함수를 활용해 outputs와 labels의 손실값 계산\n        loss = criterion(outputs, labels)\n        # 현재 배치에서의 손실 추가\n        epoch_loss += loss.item() \n        # 역전파 수행\n        loss.backward()\n        # 가중치 갱신\n        optimizer.step()\n        \n    print(f'에폭 [{epoch+1}/{epochs}] - 손실값: {epoch_loss/len(loader_train):.4f}')","metadata":{"execution":{"iopub.status.busy":"2023-01-30T06:41:57.173931Z","iopub.execute_input":"2023-01-30T06:41:57.174380Z","iopub.status.idle":"2023-01-30T07:26:31.813782Z","shell.execute_reply.started":"2023-01-30T06:41:57.174342Z","shell.execute_reply":"2023-01-30T07:26:31.812557Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import roc_auc_score # ROC AUC 점수 계산 함수 임포트\n\n# 실제값과 예측 확률값을 담을 리스트 초기화\ntrue_list = []\npreds_list = []\n\nmodel.eval() # 모델을 평가 상태로 설정 \n\nwith torch.no_grad(): # 기울기 계산 비활성화\n    for images, labels in loader_valid:\n        # 이미지, 레이블 데이터 미니배치를 장비에 할당 \n        images = images.to(device)\n        labels = labels.to(device)\n        \n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        preds = torch.softmax(outputs.cpu(), dim=1)[:, 1] # 예측 확률값\n        true = labels.cpu() # 실제값 \n        # 예측 확률값과 실제값을 리스트에 추가\n        preds_list.extend(preds)\n        true_list.extend(true)\n        \n# 검증 데이터 ROC AUC 점수 계산 \nprint(f'검증 데이터 ROC AUC : {roc_auc_score(true_list, preds_list):.4f}') ","metadata":{"execution":{"iopub.status.busy":"2023-01-30T07:26:31.816168Z","iopub.execute_input":"2023-01-30T07:26:31.817157Z","iopub.status.idle":"2023-01-30T07:26:33.875033Z","shell.execute_reply.started":"2023-01-30T07:26:31.817116Z","shell.execute_reply":"2023-01-30T07:26:33.873828Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_test = ImageDataset(df=submission, img_dir='test/', \n                            transform=transform_test)\nloader_test = DataLoader(dataset=dataset_test, batch_size=32, shuffle=False)\n\n# 예측 수행\nmodel.eval() # 모델을 평가 상태로 설정\n\npreds = [] # 타깃 예측값 저장용 리스트 초기화\n\nwith torch.no_grad(): # 기울기 계산 비활성화\n    for images, _ in loader_test:\n        # 이미지 데이터 미니배치를 장비에 할당\n        images = images.to(device)\n        \n        # 순전파 : 이미지 데이터를 신경망 모델의 입력값으로 사용해 출력값 계산\n        outputs = model(images)\n        # 타깃값이 1일 확률(예측값)\n        preds_part = torch.softmax(outputs.cpu(), dim=1)[:, 1].tolist()\n        # preds에 preds_part 이어붙이기\n        preds.extend(preds_part)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T07:31:09.964587Z","iopub.execute_input":"2023-01-30T07:31:09.964968Z","iopub.status.idle":"2023-01-30T07:31:15.765969Z","shell.execute_reply.started":"2023-01-30T07:31:09.964937Z","shell.execute_reply":"2023-01-30T07:31:15.764302Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['has_cactus'] = preds\nsubmission.to_csv('submission.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-01-30T07:32:17.731750Z","iopub.execute_input":"2023-01-30T07:32:17.732180Z","iopub.status.idle":"2023-01-30T07:32:17.754659Z","shell.execute_reply.started":"2023-01-30T07:32:17.732147Z","shell.execute_reply":"2023-01-30T07:32:17.753796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\n\nshutil.rmtree('./train')\nshutil.rmtree('./test')","metadata":{"execution":{"iopub.status.busy":"2023-01-30T07:32:19.428524Z","iopub.execute_input":"2023-01-30T07:32:19.428921Z","iopub.status.idle":"2023-01-30T07:32:20.034926Z","shell.execute_reply.started":"2023-01-30T07:32:19.428862Z","shell.execute_reply":"2023-01-30T07:32:20.033935Z"},"trusted":true},"execution_count":null,"outputs":[]}]}