{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-11-14T09:21:49.708417Z","iopub.execute_input":"2022-11-14T09:21:49.708898Z","iopub.status.idle":"2022-11-14T09:21:49.739428Z","shell.execute_reply.started":"2022-11-14T09:21:49.708786Z","shell.execute_reply":"2022-11-14T09:21:49.738438Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/porto-seguro-safe-driver-prediction/sample_submission.csv\n/kaggle/input/porto-seguro-safe-driver-prediction/train.csv\n/kaggle/input/porto-seguro-safe-driver-prediction/test.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"import pandas as pd\n\ndata_path = '/kaggle/input/porto-seguro-safe-driver-prediction/'\n\ntrain = pd.read_csv(data_path + 'train.csv', index_col='id')\ntest = pd.read_csv(data_path + 'test.csv', index_col='id')\nsubmission = pd.read_csv(data_path + 'sample_submission.csv', index_col='id')","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:21:49.740907Z","iopub.execute_input":"2022-11-14T09:21:49.741678Z","iopub.status.idle":"2022-11-14T09:22:00.951776Z","shell.execute_reply.started":"2022-11-14T09:21:49.741644Z","shell.execute_reply":"2022-11-14T09:22:00.950537Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"all_data = pd.concat([train, test], ignore_index=True)\nall_data = all_data.drop('target', axis=1)\n\nall_features = all_data.columns","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:00.953785Z","iopub.execute_input":"2022-11-14T09:22:00.954132Z","iopub.status.idle":"2022-11-14T09:22:02.277587Z","shell.execute_reply.started":"2022-11-14T09:22:00.954103Z","shell.execute_reply":"2022-11-14T09:22:02.276574Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"all_data.head()","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:02.279200Z","iopub.execute_input":"2022-11-14T09:22:02.279662Z","iopub.status.idle":"2022-11-14T09:22:02.308141Z","shell.execute_reply.started":"2022-11-14T09:22:02.279621Z","shell.execute_reply":"2022-11-14T09:22:02.307356Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"   ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n0          2              2          5              1              0   \n1          1              1          7              0              0   \n2          5              4          9              1              0   \n3          0              1          2              0              0   \n4          0              2          0              1              0   \n\n   ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  ps_ind_10_bin  \\\n0              0              1              0              0              0   \n1              0              0              1              0              0   \n2              0              0              1              0              0   \n3              1              0              0              0              0   \n4              1              0              0              0              0   \n\n   ...  ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n0  ...           9           1           5           8               0   \n1  ...           3           1           1           9               0   \n2  ...           4           2           7           7               0   \n3  ...           2           2           4           9               0   \n4  ...           3           1           1           3               0   \n\n   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n0               1               1               0               0   \n1               1               1               0               1   \n2               1               1               0               1   \n3               0               0               0               0   \n4               0               0               1               1   \n\n   ps_calc_20_bin  \n0               1  \n1               0  \n2               0  \n3               0  \n4               0  \n\n[5 rows x 57 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ps_ind_01</th>\n      <th>ps_ind_02_cat</th>\n      <th>ps_ind_03</th>\n      <th>ps_ind_04_cat</th>\n      <th>ps_ind_05_cat</th>\n      <th>ps_ind_06_bin</th>\n      <th>ps_ind_07_bin</th>\n      <th>ps_ind_08_bin</th>\n      <th>ps_ind_09_bin</th>\n      <th>ps_ind_10_bin</th>\n      <th>...</th>\n      <th>ps_calc_11</th>\n      <th>ps_calc_12</th>\n      <th>ps_calc_13</th>\n      <th>ps_calc_14</th>\n      <th>ps_calc_15_bin</th>\n      <th>ps_calc_16_bin</th>\n      <th>ps_calc_17_bin</th>\n      <th>ps_calc_18_bin</th>\n      <th>ps_calc_19_bin</th>\n      <th>ps_calc_20_bin</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>9</td>\n      <td>1</td>\n      <td>5</td>\n      <td>8</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>4</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>4</td>\n      <td>2</td>\n      <td>7</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>4</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 57 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import OneHotEncoder\n\ncat_features = [feature for feature in all_features if 'cat' in feature]\n\nonehot_encoder = OneHotEncoder()\nencoded_cat_matrix = onehot_encoder.fit_transform(all_data[cat_features])","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:02.311041Z","iopub.execute_input":"2022-11-14T09:22:02.312174Z","iopub.status.idle":"2022-11-14T09:22:05.080513Z","shell.execute_reply.started":"2022-11-14T09:22:02.312129Z","shell.execute_reply":"2022-11-14T09:22:05.079321Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"all_data['num_missing'] = (all_data==-1).sum(axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:05.081960Z","iopub.execute_input":"2022-11-14T09:22:05.082429Z","iopub.status.idle":"2022-11-14T09:22:05.295708Z","shell.execute_reply.started":"2022-11-14T09:22:05.082388Z","shell.execute_reply":"2022-11-14T09:22:05.294604Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"all_data","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:05.296822Z","iopub.execute_input":"2022-11-14T09:22:05.299059Z","iopub.status.idle":"2022-11-14T09:22:05.676232Z","shell.execute_reply.started":"2022-11-14T09:22:05.299020Z","shell.execute_reply":"2022-11-14T09:22:05.675088Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"         ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  ps_ind_05_cat  \\\n0                2              2          5              1              0   \n1                1              1          7              0              0   \n2                5              4          9              1              0   \n3                0              1          2              0              0   \n4                0              2          0              1              0   \n...            ...            ...        ...            ...            ...   \n1488023          0              1          6              0              0   \n1488024          5              3          5              1              0   \n1488025          0              1          5              0              0   \n1488026          6              1          5              1              0   \n1488027          7              1          4              1              0   \n\n         ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  \\\n0                    0              1              0              0   \n1                    0              0              1              0   \n2                    0              0              1              0   \n3                    1              0              0              0   \n4                    1              0              0              0   \n...                ...            ...            ...            ...   \n1488023              0              1              0              0   \n1488024              0              0              1              0   \n1488025              1              0              0              0   \n1488026              0              0              0              1   \n1488027              0              0              0              1   \n\n         ps_ind_10_bin  ...  ps_calc_12  ps_calc_13  ps_calc_14  \\\n0                    0  ...           1           5           8   \n1                    0  ...           1           1           9   \n2                    0  ...           2           7           7   \n3                    0  ...           2           4           9   \n4                    0  ...           1           1           3   \n...                ...  ...         ...         ...         ...   \n1488023              0  ...           2           3           4   \n1488024              0  ...           2           2          11   \n1488025              0  ...           2           2          11   \n1488026              0  ...           1           2           7   \n1488027              0  ...           2           2           7   \n\n         ps_calc_15_bin  ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  \\\n0                     0               1               1               0   \n1                     0               1               1               0   \n2                     0               1               1               0   \n3                     0               0               0               0   \n4                     0               0               0               1   \n...                 ...             ...             ...             ...   \n1488023               0               1               0               0   \n1488024               0               0               1               1   \n1488025               0               1               1               0   \n1488026               1               1               0               0   \n1488027               0               1               1               1   \n\n         ps_calc_19_bin  ps_calc_20_bin  num_missing  \n0                     0               1            1  \n1                     1               0            2  \n2                     1               0            3  \n3                     0               0            0  \n4                     1               0            2  \n...                 ...             ...          ...  \n1488023               1               0            1  \n1488024               0               0            1  \n1488025               0               0            2  \n1488026               0               0            1  \n1488027               0               0            0  \n\n[1488028 rows x 58 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ps_ind_01</th>\n      <th>ps_ind_02_cat</th>\n      <th>ps_ind_03</th>\n      <th>ps_ind_04_cat</th>\n      <th>ps_ind_05_cat</th>\n      <th>ps_ind_06_bin</th>\n      <th>ps_ind_07_bin</th>\n      <th>ps_ind_08_bin</th>\n      <th>ps_ind_09_bin</th>\n      <th>ps_ind_10_bin</th>\n      <th>...</th>\n      <th>ps_calc_12</th>\n      <th>ps_calc_13</th>\n      <th>ps_calc_14</th>\n      <th>ps_calc_15_bin</th>\n      <th>ps_calc_16_bin</th>\n      <th>ps_calc_17_bin</th>\n      <th>ps_calc_18_bin</th>\n      <th>ps_calc_19_bin</th>\n      <th>ps_calc_20_bin</th>\n      <th>num_missing</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>5</td>\n      <td>8</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>1</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>9</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5</td>\n      <td>4</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>7</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>4</td>\n      <td>9</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1488023</th>\n      <td>0</td>\n      <td>1</td>\n      <td>6</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>3</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1488024</th>\n      <td>5</td>\n      <td>3</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1488025</th>\n      <td>0</td>\n      <td>1</td>\n      <td>5</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>11</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1488026</th>\n      <td>6</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2</td>\n      <td>7</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1488027</th>\n      <td>7</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2</td>\n      <td>2</td>\n      <td>7</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1488028 rows × 58 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"remaining_features = [feature for feature in all_features if ('cat' not in feature and 'calc' not in feature)]\n\nremaining_features.append('num_missing')","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:05.678013Z","iopub.execute_input":"2022-11-14T09:22:05.678367Z","iopub.status.idle":"2022-11-14T09:22:05.683794Z","shell.execute_reply.started":"2022-11-14T09:22:05.678338Z","shell.execute_reply":"2022-11-14T09:22:05.682735Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"ind_features = [feature for feature in all_features if 'ind' in feature]\n\nis_first_feature = True\nfor ind_feature in ind_features:\n    if is_first_feature:\n        all_data['mix_ind'] = all_data[ind_feature].astype(str) + '_'\n        is_first_feature = False\n    else:\n        all_data['mix_ind'] += all_data[ind_feature].astype(str) + '_'","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:05.685402Z","iopub.execute_input":"2022-11-14T09:22:05.685698Z","iopub.status.idle":"2022-11-14T09:22:28.508735Z","shell.execute_reply.started":"2022-11-14T09:22:05.685671Z","shell.execute_reply":"2022-11-14T09:22:28.507740Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"all_data['mix_ind']","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:28.510024Z","iopub.execute_input":"2022-11-14T09:22:28.510967Z","iopub.status.idle":"2022-11-14T09:22:28.520261Z","shell.execute_reply.started":"2022-11-14T09:22:28.510931Z","shell.execute_reply":"2022-11-14T09:22:28.519114Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"0          2_2_5_1_0_0_1_0_0_0_0_0_0_0_11_0_1_0_\n1           1_1_7_0_0_0_0_1_0_0_0_0_0_0_3_0_0_1_\n2          5_4_9_1_0_0_0_1_0_0_0_0_0_0_12_1_0_0_\n3           0_1_2_0_0_1_0_0_0_0_0_0_0_0_8_1_0_0_\n4           0_2_0_1_0_1_0_0_0_0_0_0_0_0_9_1_0_0_\n                           ...                  \n1488023     0_1_6_0_0_0_1_0_0_0_0_0_0_0_2_0_0_1_\n1488024    5_3_5_1_0_0_0_1_0_0_0_0_0_0_11_1_0_0_\n1488025     0_1_5_0_0_1_0_0_0_0_0_0_0_0_5_0_0_1_\n1488026    6_1_5_1_0_0_0_0_1_0_0_0_0_0_13_1_0_0_\n1488027    7_1_4_1_0_0_0_0_1_0_0_0_0_0_12_1_0_0_\nName: mix_ind, Length: 1488028, dtype: object"},"metadata":{}}]},{"cell_type":"code","source":"all_data['ps_ind_02_cat'].value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:28.523830Z","iopub.execute_input":"2022-11-14T09:22:28.524224Z","iopub.status.idle":"2022-11-14T09:22:28.544644Z","shell.execute_reply.started":"2022-11-14T09:22:28.524193Z","shell.execute_reply":"2022-11-14T09:22:28.543526Z"},"trusted":true},"execution_count":11,"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":" 1    1079327\n 2     309747\n 3      70172\n 4      28259\n-1        523\nName: ps_ind_02_cat, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"all_data['ps_ind_02_cat'].value_counts().to_dict()","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:28.546525Z","iopub.execute_input":"2022-11-14T09:22:28.546914Z","iopub.status.idle":"2022-11-14T09:22:28.570588Z","shell.execute_reply.started":"2022-11-14T09:22:28.546876Z","shell.execute_reply":"2022-11-14T09:22:28.569418Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{1: 1079327, 2: 309747, 3: 70172, 4: 28259, -1: 523}"},"metadata":{}}]},{"cell_type":"code","source":"cat_count_features = []\nfor feature in cat_features + ['mix_ind']:\n    val_counts_dict = all_data[feature].value_counts().to_dict()\n    all_data[f'{feature}_count'] = all_data[feature].apply(lambda x:val_counts_dict[x])\n    cat_count_features.append(f'{feature}_count')","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:28.571718Z","iopub.execute_input":"2022-11-14T09:22:28.572002Z","iopub.status.idle":"2022-11-14T09:22:38.720608Z","shell.execute_reply.started":"2022-11-14T09:22:28.571976Z","shell.execute_reply":"2022-11-14T09:22:38.719426Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"cat_count_features","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:38.721965Z","iopub.execute_input":"2022-11-14T09:22:38.722391Z","iopub.status.idle":"2022-11-14T09:22:38.729127Z","shell.execute_reply.started":"2022-11-14T09:22:38.722361Z","shell.execute_reply":"2022-11-14T09:22:38.727969Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"['ps_ind_02_cat_count',\n 'ps_ind_04_cat_count',\n 'ps_ind_05_cat_count',\n 'ps_car_01_cat_count',\n 'ps_car_02_cat_count',\n 'ps_car_03_cat_count',\n 'ps_car_04_cat_count',\n 'ps_car_05_cat_count',\n 'ps_car_06_cat_count',\n 'ps_car_07_cat_count',\n 'ps_car_08_cat_count',\n 'ps_car_09_cat_count',\n 'ps_car_10_cat_count',\n 'ps_car_11_cat_count',\n 'mix_ind_count']"},"metadata":{}}]},{"cell_type":"code","source":"from scipy import sparse\ndrop_features = ['ps_ind_14', 'ps_ind_10_bin', 'ps_ind_11_bin', 'ps_ind_12_bin', 'ps_ind_13_bin', 'ps_car_14']\n\nall_data_remaining = all_data[remaining_features + cat_count_features].drop(drop_features, axis=1)\n\nall_data_sprs = sparse.hstack([sparse.csr_matrix(all_data_remaining),\n                               encoded_cat_matrix], format='csr')","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:38.730647Z","iopub.execute_input":"2022-11-14T09:22:38.731036Z","iopub.status.idle":"2022-11-14T09:22:44.770955Z","shell.execute_reply.started":"2022-11-14T09:22:38.730998Z","shell.execute_reply":"2022-11-14T09:22:44.769784Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"num_train = len(train)\n\nX = all_data_sprs[:num_train]\nX_test = all_data_sprs[num_train:]\n\ny = train['target'].values","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:44.773258Z","iopub.execute_input":"2022-11-14T09:22:44.774076Z","iopub.status.idle":"2022-11-14T09:22:45.996313Z","shell.execute_reply.started":"2022-11-14T09:22:44.774039Z","shell.execute_reply":"2022-11-14T09:22:45.995136Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"import lightgbm as lgb\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n\nbayes_dtrain = lgb.Dataset(X_train, y_train)\nbayes_dvalid = lgb.Dataset(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:45.997749Z","iopub.execute_input":"2022-11-14T09:22:45.998088Z","iopub.status.idle":"2022-11-14T09:22:47.044473Z","shell.execute_reply.started":"2022-11-14T09:22:45.998057Z","shell.execute_reply":"2022-11-14T09:22:47.043262Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"<style type='text/css'>\n.datatable table.frame { margin-bottom: 0; }\n.datatable table.frame thead { border-bottom: none; }\n.datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n.datatable .bool    { background: #DDDD99; }\n.datatable .object  { background: #565656; }\n.datatable .int     { background: #5D9E5D; }\n.datatable .float   { background: #4040CC; }\n.datatable .str     { background: #CC4040; }\n.datatable .time    { background: #40CC40; }\n.datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n.datatable .frame tbody td { text-align: left; }\n.datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n.datatable th:nth-child(2) { padding-left: 12px; }\n.datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n.datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n.datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n.datatable .sp {  opacity: 0.25;}\n.datatable .footer { font-size: 9px; }\n.datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n</style>\n"},"metadata":{}}]},{"cell_type":"code","source":"# 베이지안 최적화를 위한 하이퍼파라미터 범위\nparam_bounds = {'num_leaves':(30,40),\n                'lambda_l1':(0.7,0.9),\n                'lambda_l2':(0.9,1),\n                'feature_fraction':(0.6,0.7),\n                'bagging_fraction':(0.6,0.9),\n                'min_child_samples':(6,10),\n                'min_child_weight':(10,40)}\n\nfixed_params = {'objective':'binary',\n                'learning_rate':0.005,\n                'bagging_freq':1,\n                'force_row_wise':True,\n                'random_state':1991}","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:47.046403Z","iopub.execute_input":"2022-11-14T09:22:47.046722Z","iopub.status.idle":"2022-11-14T09:22:47.052881Z","shell.execute_reply.started":"2022-11-14T09:22:47.046694Z","shell.execute_reply":"2022-11-14T09:22:47.051685Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\ndef eval_gini(y_true, y_pred):\n    assert y_true.shape == y_pred.shape\n    \n    n_samples = y_true.shape[0]\n    L_mid = np.linspace(1 / n_samples, 1, n_samples)\n    \n    # 1) 예측값에 대한 지니계수\n    pred_order = y_true[y_pred.argsort()]\n    L_pred = np.cumsum(pred_order) / np.sum(pred_order)\n    G_pred = np.sum(L_mid - L_pred)\n    \n    # 2) 예측이 완벽할 때 지니계수\n    true_order = y_true[y_true.argsort()]\n    L_true = np.cumsum(true_order) / np.sum(true_order)\n    G_true = np.sum(L_mid - L_true)\n    \n    # 정규화된 지니계수\n    return G_pred / G_true","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:47.054309Z","iopub.execute_input":"2022-11-14T09:22:47.054699Z","iopub.status.idle":"2022-11-14T09:22:47.067721Z","shell.execute_reply.started":"2022-11-14T09:22:47.054661Z","shell.execute_reply":"2022-11-14T09:22:47.066602Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# LightGBM용 gini() 함수\ndef gini(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'gini', eval_gini(labels, preds), True","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:47.068700Z","iopub.execute_input":"2022-11-14T09:22:47.069100Z","iopub.status.idle":"2022-11-14T09:22:47.078829Z","shell.execute_reply.started":"2022-11-14T09:22:47.069069Z","shell.execute_reply":"2022-11-14T09:22:47.077765Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"def eval_function(num_leaves, lambda_l1, lambda_l2, feature_fraction, bagging_fraction, min_child_samples, min_child_weight):\n    \n    # 베이지안 최적화를 수행할 하이퍼파라미터\n    params = {'num_leaves':int(round(num_leaves)),\n              'lambda_l1':lambda_l1,\n              'lambda_l2':lambda_l2,\n              'feature_fraction':feature_fraction,\n              'bagging_fraction':bagging_fraction,\n              'min_child_samples':int(round(min_child_samples)),\n              'min_child_weight':min_child_weight,\n              'feature_pre_filter':False}\n    \n    # 고정된 하이퍼파라미터도 추가\n    params.update(fixed_params)\n    \n    print('하이퍼파라미터:', params)\n    \n    lgb_model = lgb.train(params=params,\n                               train_set=bayes_dtrain,\n                               num_boost_round=2500,\n                               valid_sets=bayes_dvalid,\n                               feval=gini,\n                               early_stopping_rounds=300,\n                               verbose_eval=False)\n    \n    # 검증 데이터로 예측 수행\n    preds = lgb_model.predict(X_valid)\n    \n    gini_score = eval_gini(y_valid, preds)\n    print(f'지니계수 {gini_score}\\n')\n    \n    return gini_score","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:47.080824Z","iopub.execute_input":"2022-11-14T09:22:47.082015Z","iopub.status.idle":"2022-11-14T09:22:47.091169Z","shell.execute_reply.started":"2022-11-14T09:22:47.081984Z","shell.execute_reply":"2022-11-14T09:22:47.090408Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"from bayes_opt import BayesianOptimization\n\noptimizer = BayesianOptimization(f=eval_function, # 평가지표 계산 함수\n                                 pbounds=param_bounds, # 하이퍼파라미터 범위\n                                 random_state=0)","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:47.092551Z","iopub.execute_input":"2022-11-14T09:22:47.092839Z","iopub.status.idle":"2022-11-14T09:22:47.124623Z","shell.execute_reply.started":"2022-11-14T09:22:47.092813Z","shell.execute_reply":"2022-11-14T09:22:47.123565Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"optimizer.maximize(init_points=3, n_iter=6)","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:22:47.126207Z","iopub.execute_input":"2022-11-14T09:22:47.126639Z","iopub.status.idle":"2022-11-14T09:53:19.093977Z","shell.execute_reply.started":"2022-11-14T09:22:47.126601Z","shell.execute_reply":"2022-11-14T09:53:19.093014Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"|   iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | min_ch... | min_ch... | num_le... |\n-------------------------------------------------------------------------------------------------------------\n하이퍼파라미터: {'num_leaves': 34, 'lambda_l1': 0.8205526752143287, 'lambda_l2': 0.9544883182996897, 'feature_fraction': 0.6715189366372419, 'bagging_fraction': 0.7646440511781974, 'min_child_samples': 8, 'min_child_weight': 29.376823391999682, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수 0.2855811556220905\n\n| \u001b[0m 1       \u001b[0m | \u001b[0m 0.2856  \u001b[0m | \u001b[0m 0.7646  \u001b[0m | \u001b[0m 0.6715  \u001b[0m | \u001b[0m 0.8206  \u001b[0m | \u001b[0m 0.9545  \u001b[0m | \u001b[0m 7.695   \u001b[0m | \u001b[0m 29.38   \u001b[0m | \u001b[0m 34.38   \u001b[0m |\n하이퍼파라미터: {'num_leaves': 39, 'lambda_l1': 0.7766883037651555, 'lambda_l2': 0.9791725038082665, 'feature_fraction': 0.6963662760501029, 'bagging_fraction': 0.867531900234624, 'min_child_samples': 8, 'min_child_weight': 27.04133683281797, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수 0.2837380537005777\n\n| \u001b[0m 2       \u001b[0m | \u001b[0m 0.2837  \u001b[0m | \u001b[0m 0.8675  \u001b[0m | \u001b[0m 0.6964  \u001b[0m | \u001b[0m 0.7767  \u001b[0m | \u001b[0m 0.9792  \u001b[0m | \u001b[0m 8.116   \u001b[0m | \u001b[0m 27.04   \u001b[0m | \u001b[0m 39.26   \u001b[0m |\n하이퍼파라미터: {'num_leaves': 40, 'lambda_l1': 0.7040436794880651, 'lambda_l2': 0.9832619845547939, 'feature_fraction': 0.608712929970154, 'bagging_fraction': 0.6213108174593661, 'min_child_samples': 9, 'min_child_weight': 36.10036444740457, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수 0.2857848354322048\n\n| \u001b[95m 3       \u001b[0m | \u001b[95m 0.2858  \u001b[0m | \u001b[95m 0.6213  \u001b[0m | \u001b[95m 0.6087  \u001b[0m | \u001b[95m 0.704   \u001b[0m | \u001b[95m 0.9833  \u001b[0m | \u001b[95m 9.113   \u001b[0m | \u001b[95m 36.1    \u001b[0m | \u001b[95m 39.79   \u001b[0m |\n하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.8444997594874222, 'lambda_l2': 0.9234023852202012, 'feature_fraction': 0.6593983245038058, 'bagging_fraction': 0.8977977822397395, 'min_child_samples': 9, 'min_child_weight': 10.549362495448534, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수 0.2828993761731121\n\n| \u001b[0m 4       \u001b[0m | \u001b[0m 0.2829  \u001b[0m | \u001b[0m 0.8978  \u001b[0m | \u001b[0m 0.6594  \u001b[0m | \u001b[0m 0.8445  \u001b[0m | \u001b[0m 0.9234  \u001b[0m | \u001b[0m 8.619   \u001b[0m | \u001b[0m 10.55   \u001b[0m | \u001b[0m 30.09   \u001b[0m |\n하이퍼파라미터: {'num_leaves': 37, 'lambda_l1': 0.7738449330497988, 'lambda_l2': 0.9032695189818599, 'feature_fraction': 0.6606341064409726, 'bagging_fraction': 0.7666713964943057, 'min_child_samples': 9, 'min_child_weight': 29.306172421380474, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수 0.28513273331754563\n\n| \u001b[0m 5       \u001b[0m | \u001b[0m 0.2851  \u001b[0m | \u001b[0m 0.7667  \u001b[0m | \u001b[0m 0.6606  \u001b[0m | \u001b[0m 0.7738  \u001b[0m | \u001b[0m 0.9033  \u001b[0m | \u001b[0m 8.769   \u001b[0m | \u001b[0m 29.31   \u001b[0m | \u001b[0m 36.6    \u001b[0m |\n하이퍼파라미터: {'num_leaves': 33, 'lambda_l1': 0.878140825240546, 'lambda_l2': 0.9, 'feature_fraction': 0.6949207801131031, 'bagging_fraction': 0.6580631827594777, 'min_child_samples': 10, 'min_child_weight': 35.85667779964393, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수 0.28531708475434286\n\n| \u001b[0m 6       \u001b[0m | \u001b[0m 0.2853  \u001b[0m | \u001b[0m 0.6581  \u001b[0m | \u001b[0m 0.6949  \u001b[0m | \u001b[0m 0.8781  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 9.826   \u001b[0m | \u001b[0m 35.86   \u001b[0m | \u001b[0m 32.8    \u001b[0m |\n하이퍼파라미터: {'num_leaves': 37, 'lambda_l1': 0.8433793375135147, 'lambda_l2': 0.9479651949974717, 'feature_fraction': 0.6859622896374784, 'bagging_fraction': 0.8362539818721497, 'min_child_samples': 6, 'min_child_weight': 39.77484183530247, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수 0.2854766974907317\n\n| \u001b[0m 7       \u001b[0m | \u001b[0m 0.2855  \u001b[0m | \u001b[0m 0.8363  \u001b[0m | \u001b[0m 0.686   \u001b[0m | \u001b[0m 0.8434  \u001b[0m | \u001b[0m 0.948   \u001b[0m | \u001b[0m 6.002   \u001b[0m | \u001b[0m 39.77   \u001b[0m | \u001b[0m 36.8    \u001b[0m |\n하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.7243619242443197, 'lambda_l2': 0.9, 'feature_fraction': 0.6, 'bagging_fraction': 0.6, 'min_child_samples': 10, 'min_child_weight': 27.951241679061347, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수 0.28455469364758784\n\n| \u001b[0m 8       \u001b[0m | \u001b[0m 0.2846  \u001b[0m | \u001b[0m 0.6     \u001b[0m | \u001b[0m 0.6     \u001b[0m | \u001b[0m 0.7244  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 27.95   \u001b[0m | \u001b[0m 30.0    \u001b[0m |\n하이퍼파라미터: {'num_leaves': 36, 'lambda_l1': 0.7, 'lambda_l2': 1.0, 'feature_fraction': 0.7, 'bagging_fraction': 0.9, 'min_child_samples': 6, 'min_child_weight': 33.90131741687068, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n[LightGBM] [Info] Number of positive: 17383, number of negative: 458786\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036506 -> initscore=-3.273091\n[LightGBM] [Info] Start training from score -3.273091\n지니계수 0.2840251406982248\n\n| \u001b[0m 9       \u001b[0m | \u001b[0m 0.284   \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 0.7     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 6.0     \u001b[0m | \u001b[0m 33.9    \u001b[0m | \u001b[0m 36.05   \u001b[0m |\n=============================================================================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"# 평가함수 점수가 최대일 때 하이퍼파라미터\nmax_params = optimizer.max['params']\nmax_params","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:53:24.903193Z","iopub.execute_input":"2022-11-14T09:53:24.903603Z","iopub.status.idle":"2022-11-14T09:53:24.912061Z","shell.execute_reply.started":"2022-11-14T09:53:24.903572Z","shell.execute_reply":"2022-11-14T09:53:24.910858Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"{'bagging_fraction': 0.6213108174593661,\n 'feature_fraction': 0.608712929970154,\n 'lambda_l1': 0.7040436794880651,\n 'lambda_l2': 0.9832619845547939,\n 'min_child_samples': 9.112627003799401,\n 'min_child_weight': 36.10036444740457,\n 'num_leaves': 39.78618342232764}"},"metadata":{}}]},{"cell_type":"code","source":"max_params['num_leaves'] = int(round(max_params['num_leaves']))\nmax_params['min_child_samples'] = int(round(max_params['min_child_samples']))","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:54:18.366137Z","iopub.execute_input":"2022-11-14T09:54:18.366551Z","iopub.status.idle":"2022-11-14T09:54:18.372448Z","shell.execute_reply.started":"2022-11-14T09:54:18.366517Z","shell.execute_reply":"2022-11-14T09:54:18.371292Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"max_params.update(fixed_params)","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:54:20.587265Z","iopub.execute_input":"2022-11-14T09:54:20.588019Z","iopub.status.idle":"2022-11-14T09:54:20.593096Z","shell.execute_reply.started":"2022-11-14T09:54:20.587982Z","shell.execute_reply":"2022-11-14T09:54:20.591995Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"max_params","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:54:23.556047Z","iopub.execute_input":"2022-11-14T09:54:23.556466Z","iopub.status.idle":"2022-11-14T09:54:23.562475Z","shell.execute_reply.started":"2022-11-14T09:54:23.556431Z","shell.execute_reply":"2022-11-14T09:54:23.561727Z"},"trusted":true},"execution_count":27,"outputs":[{"execution_count":27,"output_type":"execute_result","data":{"text/plain":"{'bagging_fraction': 0.6213108174593661,\n 'feature_fraction': 0.608712929970154,\n 'lambda_l1': 0.7040436794880651,\n 'lambda_l2': 0.9832619845547939,\n 'min_child_samples': 9,\n 'min_child_weight': 36.10036444740457,\n 'num_leaves': 40,\n 'objective': 'binary',\n 'learning_rate': 0.005,\n 'bagging_freq': 1,\n 'force_row_wise': True,\n 'random_state': 1991}"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\n# 층화 K 폴드 교차 검증기 생성\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)\n\n# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_val_preds = np.zeros(X.shape[0])\n\n# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\noof_test_preds = np.zeros(X_test.shape[0])\n\n# OOF 방식으로 모델 훈련, 검증, 예측\nfor idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n    print('#' * 40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#' * 40)\n    \n    # 훈련용 데이터, 검증용 데이터 설정\n    X_train, y_train = X[train_idx], y[train_idx]\n    X_valid, y_valid = X[valid_idx], y[valid_idx]\n    \n    # LightGBM 전용 데이터셋 생성\n    dtrain = lgb.Dataset(X_train, y_train)\n    dvalid = lgb.Dataset(X_valid, y_valid)\n    \n    lgb_model = lgb.train(params=max_params, # 최적 파라미터\n                          train_set=dtrain, # 훈련 데이터셋\n                          num_boost_round=2500, # 부스팅 반복 횟수\n                          valid_sets=dvalid, # 성능 평가용 검증 데이터셋\n                          feval=gini, # 검증용 평가지표\n                          early_stopping_rounds=300, # 조기종료 조건\n                          verbose_eval=100) # 100번째마다 점수 출력\n    \n    # 테스트 데이터를 활용해 OOF 예측\n    oof_test_preds += lgb_model.predict(X_test)/folds.n_splits\n    \n    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측\n    oof_val_preds[valid_idx] += lgb_model.predict(X_valid)\n    \n    # 검증 데이터 예측 확률에 대한 정규화 지니계수\n    gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n    print(f'폴드 {idx+1} 지니계수 : {gini_score}\\n')","metadata":{"execution":{"iopub.status.busy":"2022-11-14T09:55:14.232284Z","iopub.execute_input":"2022-11-14T09:55:14.232660Z","iopub.status.idle":"2022-11-14T10:18:11.849034Z","shell.execute_reply.started":"2022-11-14T09:55:14.232630Z","shell.execute_reply":"2022-11-14T10:18:11.847720Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"######################################## 폴드 1 / 폴드 5 ########################################\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n/opt/conda/lib/python3.7/site-packages/lightgbm/engine.py:239: UserWarning: 'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. Pass 'log_evaluation()' callback via 'callbacks' argument instead.\n  _log_warning(\"'verbose_eval' argument is deprecated and will be removed in a future release of LightGBM. \"\n","output_type":"stream"},{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 17355, number of negative: 458814\n[LightGBM] [Info] Total Bins 1554\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 216\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036447 -> initscore=-3.274764\n[LightGBM] [Info] Start training from score -3.274764\nTraining until validation scores don't improve for 300 rounds\n[100]\tvalid_0's binary_logloss: 0.154239\tvalid_0's gini: 0.270944\n[200]\tvalid_0's binary_logloss: 0.153176\tvalid_0's gini: 0.275764\n[300]\tvalid_0's binary_logloss: 0.152584\tvalid_0's gini: 0.279501\n[400]\tvalid_0's binary_logloss: 0.152222\tvalid_0's gini: 0.282893\n[500]\tvalid_0's binary_logloss: 0.151986\tvalid_0's gini: 0.286058\n[600]\tvalid_0's binary_logloss: 0.151824\tvalid_0's gini: 0.288805\n[700]\tvalid_0's binary_logloss: 0.151712\tvalid_0's gini: 0.290719\n[800]\tvalid_0's binary_logloss: 0.151622\tvalid_0's gini: 0.292581\n[900]\tvalid_0's binary_logloss: 0.151552\tvalid_0's gini: 0.294212\n[1000]\tvalid_0's binary_logloss: 0.151505\tvalid_0's gini: 0.295204\n[1100]\tvalid_0's binary_logloss: 0.151471\tvalid_0's gini: 0.295909\n[1200]\tvalid_0's binary_logloss: 0.151438\tvalid_0's gini: 0.296721\n[1300]\tvalid_0's binary_logloss: 0.151414\tvalid_0's gini: 0.297335\n[1400]\tvalid_0's binary_logloss: 0.151402\tvalid_0's gini: 0.297569\n[1500]\tvalid_0's binary_logloss: 0.15139\tvalid_0's gini: 0.297881\n[1600]\tvalid_0's binary_logloss: 0.151382\tvalid_0's gini: 0.298033\n[1700]\tvalid_0's binary_logloss: 0.151376\tvalid_0's gini: 0.298238\n[1800]\tvalid_0's binary_logloss: 0.151372\tvalid_0's gini: 0.298342\n[1900]\tvalid_0's binary_logloss: 0.151369\tvalid_0's gini: 0.298371\n[2000]\tvalid_0's binary_logloss: 0.151371\tvalid_0's gini: 0.298222\n[2100]\tvalid_0's binary_logloss: 0.151362\tvalid_0's gini: 0.298463\n[2200]\tvalid_0's binary_logloss: 0.151359\tvalid_0's gini: 0.298466\n[2300]\tvalid_0's binary_logloss: 0.151362\tvalid_0's gini: 0.298415\n[2400]\tvalid_0's binary_logloss: 0.151359\tvalid_0's gini: 0.298569\n[2500]\tvalid_0's binary_logloss: 0.151361\tvalid_0's gini: 0.298542\nDid not meet early stopping. Best iteration is:\n[2458]\tvalid_0's binary_logloss: 0.151355\tvalid_0's gini: 0.29865\n폴드 1 지니계수 : 0.2986504843987991\n\n######################################## 폴드 2 / 폴드 5 ########################################\n[LightGBM] [Info] Number of positive: 17355, number of negative: 458814\n[LightGBM] [Info] Total Bins 1560\n[LightGBM] [Info] Number of data points in the train set: 476169, number of used features: 216\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036447 -> initscore=-3.274764\n[LightGBM] [Info] Start training from score -3.274764\nTraining until validation scores don't improve for 300 rounds\n[100]\tvalid_0's binary_logloss: 0.154347\tvalid_0's gini: 0.258575\n[200]\tvalid_0's binary_logloss: 0.153338\tvalid_0's gini: 0.263768\n[300]\tvalid_0's binary_logloss: 0.152804\tvalid_0's gini: 0.267635\n[400]\tvalid_0's binary_logloss: 0.152483\tvalid_0's gini: 0.271009\n[500]\tvalid_0's binary_logloss: 0.152299\tvalid_0's gini: 0.27324\n[600]\tvalid_0's binary_logloss: 0.152157\tvalid_0's gini: 0.275756\n[700]\tvalid_0's binary_logloss: 0.15206\tvalid_0's gini: 0.277655\n[800]\tvalid_0's binary_logloss: 0.151986\tvalid_0's gini: 0.279371\n[900]\tvalid_0's binary_logloss: 0.151942\tvalid_0's gini: 0.280359\n[1000]\tvalid_0's binary_logloss: 0.151898\tvalid_0's gini: 0.281475\n[1100]\tvalid_0's binary_logloss: 0.15186\tvalid_0's gini: 0.282482\n[1200]\tvalid_0's binary_logloss: 0.151835\tvalid_0's gini: 0.283198\n[1300]\tvalid_0's binary_logloss: 0.15181\tvalid_0's gini: 0.283848\n[1400]\tvalid_0's binary_logloss: 0.151796\tvalid_0's gini: 0.284221\n[1500]\tvalid_0's binary_logloss: 0.151781\tvalid_0's gini: 0.284645\n[1600]\tvalid_0's binary_logloss: 0.15177\tvalid_0's gini: 0.284943\n[1700]\tvalid_0's binary_logloss: 0.151761\tvalid_0's gini: 0.285129\n[1800]\tvalid_0's binary_logloss: 0.151755\tvalid_0's gini: 0.28522\n[1900]\tvalid_0's binary_logloss: 0.151752\tvalid_0's gini: 0.285325\n[2000]\tvalid_0's binary_logloss: 0.151749\tvalid_0's gini: 0.285504\n[2100]\tvalid_0's binary_logloss: 0.151748\tvalid_0's gini: 0.285633\n[2200]\tvalid_0's binary_logloss: 0.151744\tvalid_0's gini: 0.285711\n[2300]\tvalid_0's binary_logloss: 0.15174\tvalid_0's gini: 0.285853\n[2400]\tvalid_0's binary_logloss: 0.15174\tvalid_0's gini: 0.28594\n[2500]\tvalid_0's binary_logloss: 0.151745\tvalid_0's gini: 0.285916\nDid not meet early stopping. Best iteration is:\n[2334]\tvalid_0's binary_logloss: 0.151736\tvalid_0's gini: 0.285929\n폴드 2 지니계수 : 0.2859292916021393\n\n######################################## 폴드 3 / 폴드 5 ########################################\n[LightGBM] [Info] Number of positive: 17356, number of negative: 458814\n[LightGBM] [Info] Total Bins 1558\n[LightGBM] [Info] Number of data points in the train set: 476170, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036449 -> initscore=-3.274707\n[LightGBM] [Info] Start training from score -3.274707\nTraining until validation scores don't improve for 300 rounds\n[100]\tvalid_0's binary_logloss: 0.15424\tvalid_0's gini: 0.263985\n[200]\tvalid_0's binary_logloss: 0.153171\tvalid_0's gini: 0.268713\n[300]\tvalid_0's binary_logloss: 0.152574\tvalid_0's gini: 0.272773\n[400]\tvalid_0's binary_logloss: 0.152223\tvalid_0's gini: 0.275785\n[500]\tvalid_0's binary_logloss: 0.152001\tvalid_0's gini: 0.278098\n[600]\tvalid_0's binary_logloss: 0.151847\tvalid_0's gini: 0.280206\n[700]\tvalid_0's binary_logloss: 0.151748\tvalid_0's gini: 0.281603\n[800]\tvalid_0's binary_logloss: 0.151682\tvalid_0's gini: 0.282672\n[900]\tvalid_0's binary_logloss: 0.151637\tvalid_0's gini: 0.283423\n[1000]\tvalid_0's binary_logloss: 0.151608\tvalid_0's gini: 0.283963\n[1100]\tvalid_0's binary_logloss: 0.151589\tvalid_0's gini: 0.284105\n[1200]\tvalid_0's binary_logloss: 0.151574\tvalid_0's gini: 0.284387\n[1300]\tvalid_0's binary_logloss: 0.151575\tvalid_0's gini: 0.284318\n[1400]\tvalid_0's binary_logloss: 0.151572\tvalid_0's gini: 0.284372\n[1500]\tvalid_0's binary_logloss: 0.151569\tvalid_0's gini: 0.284466\n[1600]\tvalid_0's binary_logloss: 0.151574\tvalid_0's gini: 0.284435\n[1700]\tvalid_0's binary_logloss: 0.151579\tvalid_0's gini: 0.284362\nEarly stopping, best iteration is:\n[1478]\tvalid_0's binary_logloss: 0.151568\tvalid_0's gini: 0.284492\n폴드 3 지니계수 : 0.2844916047790675\n\n######################################## 폴드 4 / 폴드 5 ########################################\n[LightGBM] [Info] Number of positive: 17355, number of negative: 458815\n[LightGBM] [Info] Total Bins 1555\n[LightGBM] [Info] Number of data points in the train set: 476170, number of used features: 216\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036447 -> initscore=-3.274766\n[LightGBM] [Info] Start training from score -3.274766\nTraining until validation scores don't improve for 300 rounds\n[100]\tvalid_0's binary_logloss: 0.154327\tvalid_0's gini: 0.256916\n[200]\tvalid_0's binary_logloss: 0.15331\tvalid_0's gini: 0.261871\n[300]\tvalid_0's binary_logloss: 0.152761\tvalid_0's gini: 0.265441\n[400]\tvalid_0's binary_logloss: 0.152441\tvalid_0's gini: 0.268613\n[500]\tvalid_0's binary_logloss: 0.152245\tvalid_0's gini: 0.271168\n[600]\tvalid_0's binary_logloss: 0.152098\tvalid_0's gini: 0.273746\n[700]\tvalid_0's binary_logloss: 0.152012\tvalid_0's gini: 0.275192\n[800]\tvalid_0's binary_logloss: 0.151952\tvalid_0's gini: 0.276278\n[900]\tvalid_0's binary_logloss: 0.151911\tvalid_0's gini: 0.277039\n[1000]\tvalid_0's binary_logloss: 0.151871\tvalid_0's gini: 0.277996\n[1100]\tvalid_0's binary_logloss: 0.151844\tvalid_0's gini: 0.278535\n[1200]\tvalid_0's binary_logloss: 0.151827\tvalid_0's gini: 0.279055\n[1300]\tvalid_0's binary_logloss: 0.151817\tvalid_0's gini: 0.27936\n[1400]\tvalid_0's binary_logloss: 0.151799\tvalid_0's gini: 0.279872\n[1500]\tvalid_0's binary_logloss: 0.151797\tvalid_0's gini: 0.280053\n[1600]\tvalid_0's binary_logloss: 0.151792\tvalid_0's gini: 0.280148\n[1700]\tvalid_0's binary_logloss: 0.151794\tvalid_0's gini: 0.280162\n[1800]\tvalid_0's binary_logloss: 0.151793\tvalid_0's gini: 0.280319\n[1900]\tvalid_0's binary_logloss: 0.151795\tvalid_0's gini: 0.280422\n[2000]\tvalid_0's binary_logloss: 0.151797\tvalid_0's gini: 0.280419\n[2100]\tvalid_0's binary_logloss: 0.151799\tvalid_0's gini: 0.280516\nEarly stopping, best iteration is:\n[1852]\tvalid_0's binary_logloss: 0.15179\tvalid_0's gini: 0.280514\n폴드 4 지니계수 : 0.2805136229288192\n\n######################################## 폴드 5 / 폴드 5 ########################################\n[LightGBM] [Info] Number of positive: 17355, number of negative: 458815\n[LightGBM] [Info] Total Bins 1558\n[LightGBM] [Info] Number of data points in the train set: 476170, number of used features: 217\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.036447 -> initscore=-3.274766\n[LightGBM] [Info] Start training from score -3.274766\nTraining until validation scores don't improve for 300 rounds\n[100]\tvalid_0's binary_logloss: 0.15439\tvalid_0's gini: 0.26681\n[200]\tvalid_0's binary_logloss: 0.15338\tvalid_0's gini: 0.272186\n[300]\tvalid_0's binary_logloss: 0.152821\tvalid_0's gini: 0.275897\n[400]\tvalid_0's binary_logloss: 0.1525\tvalid_0's gini: 0.278734\n[500]\tvalid_0's binary_logloss: 0.152277\tvalid_0's gini: 0.282151\n[600]\tvalid_0's binary_logloss: 0.15212\tvalid_0's gini: 0.285039\n[700]\tvalid_0's binary_logloss: 0.152009\tvalid_0's gini: 0.287435\n[800]\tvalid_0's binary_logloss: 0.15192\tvalid_0's gini: 0.289549\n[900]\tvalid_0's binary_logloss: 0.151862\tvalid_0's gini: 0.290886\n[1000]\tvalid_0's binary_logloss: 0.151819\tvalid_0's gini: 0.291935\n[1100]\tvalid_0's binary_logloss: 0.151782\tvalid_0's gini: 0.292972\n[1200]\tvalid_0's binary_logloss: 0.151752\tvalid_0's gini: 0.293784\n[1300]\tvalid_0's binary_logloss: 0.151732\tvalid_0's gini: 0.294315\n[1400]\tvalid_0's binary_logloss: 0.151724\tvalid_0's gini: 0.294475\n[1500]\tvalid_0's binary_logloss: 0.151713\tvalid_0's gini: 0.294786\n[1600]\tvalid_0's binary_logloss: 0.1517\tvalid_0's gini: 0.295146\n[1700]\tvalid_0's binary_logloss: 0.151694\tvalid_0's gini: 0.295268\n[1800]\tvalid_0's binary_logloss: 0.151695\tvalid_0's gini: 0.295212\n[1900]\tvalid_0's binary_logloss: 0.151689\tvalid_0's gini: 0.295454\n[2000]\tvalid_0's binary_logloss: 0.151693\tvalid_0's gini: 0.2954\n[2100]\tvalid_0's binary_logloss: 0.151694\tvalid_0's gini: 0.295427\n[2200]\tvalid_0's binary_logloss: 0.151692\tvalid_0's gini: 0.295538\n[2300]\tvalid_0's binary_logloss: 0.151699\tvalid_0's gini: 0.295411\nEarly stopping, best iteration is:\n[2045]\tvalid_0's binary_logloss: 0.151689\tvalid_0's gini: 0.295553\n폴드 5 지니계수 : 0.29555250456072807\n\n","output_type":"stream"}]},{"cell_type":"code","source":"print('OOF 검증 데이터 지니계수 : ', eval_gini(y, oof_val_preds))","metadata":{"execution":{"iopub.status.busy":"2022-11-14T10:18:43.688471Z","iopub.execute_input":"2022-11-14T10:18:43.688917Z","iopub.status.idle":"2022-11-14T10:18:43.801686Z","shell.execute_reply.started":"2022-11-14T10:18:43.688880Z","shell.execute_reply":"2022-11-14T10:18:43.800849Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"OOF 검증 데이터 지니계수 :  0.2889651000887542\n","output_type":"stream"}]},{"cell_type":"code","source":"submission['target'] = oof_test_preds\nsubmission.to_csv('submission.csv')","metadata":{"execution":{"iopub.status.busy":"2022-11-14T10:18:45.567088Z","iopub.execute_input":"2022-11-14T10:18:45.568195Z","iopub.status.idle":"2022-11-14T10:18:47.799724Z","shell.execute_reply.started":"2022-11-14T10:18:45.568154Z","shell.execute_reply":"2022-11-14T10:18:47.798566Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"# LightGBM용 gini() 함수\ndef gini(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'gini', eval_gini(labels, preds), True","metadata":{"execution":{"iopub.status.busy":"2022-11-14T10:21:39.117647Z","iopub.execute_input":"2022-11-14T10:21:39.119017Z","iopub.status.idle":"2022-11-14T10:21:39.124673Z","shell.execute_reply.started":"2022-11-14T10:21:39.118965Z","shell.execute_reply":"2022-11-14T10:21:39.123621Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# XGBoost용 gini() 함수\ndef gini(preds, dtrain):\n    labels = dtrain.get_label()\n    return 'gini', eval_gini(labels, preds)","metadata":{"execution":{"iopub.status.busy":"2022-11-14T10:21:41.108900Z","iopub.execute_input":"2022-11-14T10:21:41.109337Z","iopub.status.idle":"2022-11-14T10:21:41.114897Z","shell.execute_reply.started":"2022-11-14T10:21:41.109303Z","shell.execute_reply":"2022-11-14T10:21:41.113691Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"import xgboost as xgb\nfrom sklearn.model_selection import train_test_split","metadata":{"execution":{"iopub.status.busy":"2022-11-14T10:21:44.633136Z","iopub.execute_input":"2022-11-14T10:21:44.633537Z","iopub.status.idle":"2022-11-14T10:21:44.731561Z","shell.execute_reply.started":"2022-11-14T10:21:44.633506Z","shell.execute_reply":"2022-11-14T10:21:44.730500Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=0)\n\nbayes_dtrain = xgb.DMatrix(X_train, y_train)\nbayes_dvalid = xgb.DMatrix(X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2022-11-14T10:21:47.171092Z","iopub.execute_input":"2022-11-14T10:21:47.172294Z","iopub.status.idle":"2022-11-14T10:21:47.793255Z","shell.execute_reply.started":"2022-11-14T10:21:47.172250Z","shell.execute_reply":"2022-11-14T10:21:47.792026Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"param_bounds = {'max_depth':(4,8),\n                'subsample':(0.6,0.9),\n                'colsample_bytree':(0.7,1.0),\n                'min_child_weight':(5,7),\n                'gamma':(8,11),\n                'reg_alpha':(7,9),\n                'reg_lambda':(1.1, 1.5),\n                'scale_pos_weight':(1.4, 1.6)}\n\nfixed_params = {'objective':'binary:logistic',\n                'learning_rate':0.2,\n                'random_state':1991}","metadata":{"execution":{"iopub.status.busy":"2022-11-14T10:21:50.043770Z","iopub.execute_input":"2022-11-14T10:21:50.044250Z","iopub.status.idle":"2022-11-14T10:21:50.051771Z","shell.execute_reply.started":"2022-11-14T10:21:50.044197Z","shell.execute_reply":"2022-11-14T10:21:50.050519Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"def eval_function(max_depth, subsample, colsample_bytree, min_child_weight, \n                  reg_alpha, gamma, reg_lambda, scale_pos_weight):\n    params = {'max_depth':int(round(max_depth)),\n              'subsample':subsample,\n              'colsample_bytree':colsample_bytree,\n              'min_child_weight':min_child_weight,\n              'gamma':gamma,\n              'reg_alpha':reg_alpha,\n              'reg_lambda':reg_lambda,\n              'scale_pos_weight':scale_pos_weight}\n    \n    params.update(fixed_params)\n    \n    print('하이퍼파라미터 :', params)\n    \n    xgb_model = xgb.train(params=params,\n                          dtrain=bayes_dtrain,\n                          num_boost_round=2000,\n                          evals=[(bayes_dvalid, 'bayes_dvalid')],\n                          maximize=True,\n                          feval=gini,\n                          early_stopping_rounds=200,\n                          verbose_eval=False)\n    \n    best_iter = xgb_model.best_iteration\n    preds = xgb_model.predict(bayes_dvalid,\n                              iteration_range=(0,best_iter))\n    \n    gini_score = eval_gini(y_valid, preds)\n    print(f'지니계수 : {gini_score}\\n')\n    \n    return gini_score","metadata":{"execution":{"iopub.status.busy":"2022-11-14T10:55:49.576193Z","iopub.execute_input":"2022-11-14T10:55:49.576691Z","iopub.status.idle":"2022-11-14T10:55:49.585449Z","shell.execute_reply.started":"2022-11-14T10:55:49.576654Z","shell.execute_reply":"2022-11-14T10:55:49.584529Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"from bayes_opt import BayesianOptimization\n\noptimizer = BayesianOptimization(f=eval_function,\n                                 pbounds=param_bounds,\n                                 random_state=0)\n\noptimizer.maximize(init_points=3, n_iter=6)","metadata":{"execution":{"iopub.status.busy":"2022-11-14T10:55:53.164313Z","iopub.execute_input":"2022-11-14T10:55:53.165387Z","iopub.status.idle":"2022-11-14T11:33:21.288432Z","shell.execute_reply.started":"2022-11-14T10:55:53.165334Z","shell.execute_reply":"2022-11-14T11:33:21.287110Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"|   iter    |  target   | colsam... |   gamma   | max_depth | min_ch... | reg_alpha | reg_la... | scale_... | subsample |\n-------------------------------------------------------------------------------------------------------------------------\n하이퍼파라미터 : {'max_depth': 6, 'subsample': 0.867531900234624, 'colsample_bytree': 0.8646440511781974, 'min_child_weight': 6.0897663659937935, 'gamma': 10.14556809911726, 'reg_alpha': 7.84730959867781, 'reg_lambda': 1.3583576452266626, 'scale_pos_weight': 1.4875174422525386, 'objective': 'binary:logistic', 'learning_rate': 0.2, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.2775751250402207\n\n| \u001b[0m 1       \u001b[0m | \u001b[0m 0.2776  \u001b[0m | \u001b[0m 0.8646  \u001b[0m | \u001b[0m 10.15   \u001b[0m | \u001b[0m 6.411   \u001b[0m | \u001b[0m 6.09    \u001b[0m | \u001b[0m 7.847   \u001b[0m | \u001b[0m 1.358   \u001b[0m | \u001b[0m 1.488   \u001b[0m | \u001b[0m 0.8675  \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.6261387899104622, 'colsample_bytree': 0.9890988281503088, 'min_child_weight': 6.0577898395058085, 'gamma': 9.150324556477333, 'reg_alpha': 8.136089122187865, 'reg_lambda': 1.4702386553170643, 'scale_pos_weight': 1.4142072116395774, 'objective': 'binary:logistic', 'learning_rate': 0.2, 'random_state': 1991}\n지니계수 : 0.27865486539271994\n\n| \u001b[95m 2       \u001b[0m | \u001b[95m 0.2787  \u001b[0m | \u001b[95m 0.9891  \u001b[0m | \u001b[95m 9.15    \u001b[0m | \u001b[95m 7.167   \u001b[0m | \u001b[95m 6.058   \u001b[0m | \u001b[95m 8.136   \u001b[0m | \u001b[95m 1.47    \u001b[0m | \u001b[95m 1.414   \u001b[0m | \u001b[95m 0.6261  \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.8341587528859367, 'colsample_bytree': 0.7060655192320977, 'min_child_weight': 6.7400242964936385, 'gamma': 10.497859536643814, 'reg_alpha': 8.957236684465528, 'reg_lambda': 1.4196634256866894, 'scale_pos_weight': 1.4922958724505864, 'objective': 'binary:logistic', 'learning_rate': 0.2, 'random_state': 1991}\n지니계수 : 0.28160193283086205\n\n| \u001b[95m 3       \u001b[0m | \u001b[95m 0.2816  \u001b[0m | \u001b[95m 0.7061  \u001b[0m | \u001b[95m 10.5    \u001b[0m | \u001b[95m 7.113   \u001b[0m | \u001b[95m 6.74    \u001b[0m | \u001b[95m 8.957   \u001b[0m | \u001b[95m 1.42    \u001b[0m | \u001b[95m 1.492   \u001b[0m | \u001b[95m 0.8342  \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.7651408657889802, 'colsample_bytree': 0.7932245335850322, 'min_child_weight': 6.629692693946201, 'gamma': 10.482878067740884, 'reg_alpha': 8.776193252251918, 'reg_lambda': 1.4016006215498609, 'scale_pos_weight': 1.4572455379402505, 'objective': 'binary:logistic', 'learning_rate': 0.2, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.28201830561931707\n\n| \u001b[95m 4       \u001b[0m | \u001b[95m 0.282   \u001b[0m | \u001b[95m 0.7932  \u001b[0m | \u001b[95m 10.48   \u001b[0m | \u001b[95m 6.989   \u001b[0m | \u001b[95m 6.63    \u001b[0m | \u001b[95m 8.776   \u001b[0m | \u001b[95m 1.402   \u001b[0m | \u001b[95m 1.457   \u001b[0m | \u001b[95m 0.7651  \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.6, 'colsample_bytree': 1.0, 'min_child_weight': 6.744295696561874, 'gamma': 11.0, 'reg_alpha': 9.0, 'reg_lambda': 1.1, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.2, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.2788718647973332\n\n| \u001b[0m 5       \u001b[0m | \u001b[0m 0.2789  \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 11.0    \u001b[0m | \u001b[0m 6.694   \u001b[0m | \u001b[0m 6.744   \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 1.1     \u001b[0m | \u001b[0m 1.4     \u001b[0m | \u001b[0m 0.6     \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.6058725502062682, 'colsample_bytree': 0.7355553309796351, 'min_child_weight': 6.613510767690425, 'gamma': 10.368671905098733, 'reg_alpha': 8.603015883077465, 'reg_lambda': 1.5, 'scale_pos_weight': 1.4, 'objective': 'binary:logistic', 'learning_rate': 0.2, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.27130363804546226\n\n| \u001b[0m 6       \u001b[0m | \u001b[0m 0.2713  \u001b[0m | \u001b[0m 0.7356  \u001b[0m | \u001b[0m 10.37   \u001b[0m | \u001b[0m 7.397   \u001b[0m | \u001b[0m 6.614   \u001b[0m | \u001b[0m 8.603   \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 1.4     \u001b[0m | \u001b[0m 0.6059  \u001b[0m |\n하이퍼파라미터 : {'max_depth': 7, 'subsample': 0.6931141936797243, 'colsample_bytree': 0.8817801730078565, 'min_child_weight': 6.992334203641873, 'gamma': 9.013424730095146, 'reg_alpha': 7.640858389939128, 'reg_lambda': 1.3562805915715632, 'scale_pos_weight': 1.449446257931491, 'objective': 'binary:logistic', 'learning_rate': 0.2, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.2770034257236857\n\n| \u001b[0m 7       \u001b[0m | \u001b[0m 0.277   \u001b[0m | \u001b[0m 0.8818  \u001b[0m | \u001b[0m 9.013   \u001b[0m | \u001b[0m 6.927   \u001b[0m | \u001b[0m 6.992   \u001b[0m | \u001b[0m 7.641   \u001b[0m | \u001b[0m 1.356   \u001b[0m | \u001b[0m 1.449   \u001b[0m | \u001b[0m 0.6931  \u001b[0m |\n하이퍼파라미터 : {'max_depth': 5, 'subsample': 0.6261564417044092, 'colsample_bytree': 0.8763145220620449, 'min_child_weight': 5.135323353557588, 'gamma': 8.39495450163982, 'reg_alpha': 8.950443047087845, 'reg_lambda': 1.4235649099168255, 'scale_pos_weight': 1.5217625173811569, 'objective': 'binary:logistic', 'learning_rate': 0.2, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.2782173405706204\n\n| \u001b[0m 8       \u001b[0m | \u001b[0m 0.2782  \u001b[0m | \u001b[0m 0.8763  \u001b[0m | \u001b[0m 8.395   \u001b[0m | \u001b[0m 4.561   \u001b[0m | \u001b[0m 5.135   \u001b[0m | \u001b[0m 8.95    \u001b[0m | \u001b[0m 1.424   \u001b[0m | \u001b[0m 1.522   \u001b[0m | \u001b[0m 0.6262  \u001b[0m |\n하이퍼파라미터 : {'max_depth': 6, 'subsample': 0.857971740304964, 'colsample_bytree': 0.9583821245229369, 'min_child_weight': 6.158305055403563, 'gamma': 9.305332775334449, 'reg_alpha': 8.200928434091152, 'reg_lambda': 1.2571039588093065, 'scale_pos_weight': 1.4700266933495618, 'objective': 'binary:logistic', 'learning_rate': 0.2, 'random_state': 1991}\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/xgboost/training.py:36: UserWarning: `feval` is deprecated, use `custom_metric` instead.  They have different behavior when custom objective is also used.See https://xgboost.readthedocs.io/en/latest/tutorials/custom_metric_obj.html for details on the `custom_metric`.\n  \"`feval` is deprecated, use `custom_metric` instead.  They have \"\n","output_type":"stream"},{"name":"stdout","text":"지니계수 : 0.2795967960609067\n\n| \u001b[0m 9       \u001b[0m | \u001b[0m 0.2796  \u001b[0m | \u001b[0m 0.9584  \u001b[0m | \u001b[0m 9.305   \u001b[0m | \u001b[0m 5.594   \u001b[0m | \u001b[0m 6.158   \u001b[0m | \u001b[0m 8.201   \u001b[0m | \u001b[0m 1.257   \u001b[0m | \u001b[0m 1.47    \u001b[0m | \u001b[0m 0.858   \u001b[0m |\n=========================================================================================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"max_params = optimizer.max['params']\nmax_params","metadata":{"execution":{"iopub.status.busy":"2022-11-14T10:54:59.225073Z","iopub.execute_input":"2022-11-14T10:54:59.225496Z","iopub.status.idle":"2022-11-14T10:54:59.244924Z","shell.execute_reply.started":"2022-11-14T10:54:59.225459Z","shell.execute_reply":"2022-11-14T10:54:59.243304Z"},"trusted":true},"execution_count":46,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2911773493.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_params\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'params'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'params'"],"ename":"KeyError","evalue":"'params'","output_type":"error"}]},{"cell_type":"code","source":"max_params['max_depth'] = int(round(max_params['max_depth']))\nmax_params.update(fixed_params)\nmax_params","metadata":{"execution":{"iopub.status.busy":"2022-11-14T10:54:53.861262Z","iopub.execute_input":"2022-11-14T10:54:53.861663Z","iopub.status.idle":"2022-11-14T10:54:53.879589Z","shell.execute_reply.started":"2022-11-14T10:54:53.861632Z","shell.execute_reply":"2022-11-14T10:54:53.878358Z"},"trusted":true},"execution_count":45,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_27/2420611810.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmax_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mat_depth'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_params\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mat_depth'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmax_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfixed_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmax_params\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'mat_depth'"],"ename":"KeyError","evalue":"'mat_depth'","output_type":"error"}]},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\n\nfolds = StratifiedKFold(n_splits=5, shuffle=True, random_state=1991)\n\noof_val_preds = np.zeros(X.shape[0])\n\noof_test_preds = np.zeros(X_test.shape[0])\n\nfor idx, (train_idx, valid_idx) in enumerate(folds.split(X,y)):\n    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#' * 40)\n    \n    X_train, y_train = X[train_idx], y[train_idx]\n    X_valid, y_valid = X[valid_idx], y[valid_idx]\n    \n    dtrain = xgb.DMatrix(X_train, y_train)\n    dvalid = xgb.DMatrix(X_valid, y_valid)\n    dtest = xgb.DMatrix(X_test)\n    \n    xgb_model = xgb.train(params=max_params,\n                          dtrain=dtrain,\n                          evals=[(dvalid, 'valid')],\n                          maximize=True,\n                          feval=gini,\n                          early_stopping_rounds=200,\n                          verbose_eval=100)\n    \n    best_iter = xgb_model.best_iteration\n    \n    oof_test_preds += xgb_model.predict(dtest, iteration_range=(0,best_iter)) / folds.n_splits\n    \n    oof_val_preds[valid_idx] += xgb_model.predict(dvalid, iteration_range=(0, best_iter))\n    \n    gini_score = eval_gini(y_valid, oof_val_preds[valid_idx])\n    print(f'폴드 {idx+1} 지니계수 : {gini_score}\\n')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print('OOF 검증 데이터 지니계수 :', eval_gini(y, oof_val_preds))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['target'] = oof_test_preds\nsubmission.to_csv('submission.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"oof_test_preds = oof_test_preds_lgb * 0.5 + oof_test_preds_xgb * 0.5","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"submission['target'] = oof_test_preds\nsubmission.to_csv('submission.csv')","metadata":{},"execution_count":null,"outputs":[]}]}